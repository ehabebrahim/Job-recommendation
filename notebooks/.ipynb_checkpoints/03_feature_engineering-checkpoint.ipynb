{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_PATH = \"../data/processed/1_preprocessed_df.pkl\"\n",
    "\n",
    "NA_STRING = 'Not Specified'\n",
    "TRANSPARENT_STRING = 'rgba(0, 0, 0, 0)'\n",
    "\n",
    "ROLE_COLS      = ['DevType']\n",
    "TECH_COLS      = ['LanguageHaveWorkedWith',\n",
    "                  'DatabaseHaveWorkedWith',\n",
    "                  'WebframeHaveWorkedWith',\n",
    "                  'MiscTechHaveWorkedWith',\n",
    "                  'ToolsTechHaveWorkedWith']\n",
    "\n",
    "EXPORT_FEATURES_DIR = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Data \n",
    "df = pd.read_pickle(DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode \n",
    "encoded_dfs = {}\n",
    "for col in ROLE_COLS + TECH_COLS:\n",
    "    binarizer = MultiLabelBinarizer()\n",
    "    encoded_df = pd.DataFrame(binarizer.fit_transform(df[col]),\n",
    "                               columns=binarizer.classes_,\n",
    "                               index=df[col].index)\n",
    "    encoded_dfs[col] = encoded_df\n",
    "    \n",
    "# Merge 1-hot encoded \n",
    "ohe_df = pd.concat(encoded_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sub data frames \n",
    "skills_ohe = ohe_df.drop('DevType', axis=1).copy()\n",
    "std_skills = StandardScaler().fit_transform(skills_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_projection = TSNE(n_components=2, \n",
    "                       perplexity=3,\n",
    "                       learning_rate=0.01,\n",
    "                       init='pca', \n",
    "                       method='barnes_hut', \n",
    "                       n_jobs=2, \n",
    "                       n_iter=10**10,\n",
    "                       random_state=0).fit_transform(std_skills.T)\n",
    "\n",
    "tsne_projection = pd.DataFrame(tsne_projection, index=skills_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_projection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(x=tsne_projection[0], y=tsne_projection[1], text=tsne_projection.droplevel(0).index)\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(height=1000, width=1000, title_text='TSNE')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_cluster = list(range(10,25))\n",
    "silhoutte_score = []\n",
    "best_cluster_model = None \n",
    "\n",
    "for n_clusters in range_n_cluster:\n",
    "    cluster_model  = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "    cluster_labels = cluster_model.fit_predict(tsne_projection)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(tsne_projection, cluster_labels)\n",
    "    silhoutte_score += [silhouette_avg]\n",
    "    \n",
    "    if silhouette_avg >= np.max(silhoutte_score):\n",
    "        best_cluster_model = cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_n_cluster, silhoutte_score)\n",
    "plt.axvline(best_cluster_model.n_clusters, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = [\"skills_group_\" + str(label) \n",
    "                 for label in best_cluster_model.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=tsne_projection[0], \n",
    "                 y=tsne_projection[1], \n",
    "                 text=tsne_projection.droplevel(0).index, \n",
    "                 color=cluster_labels)\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(height=800, width=800, title_text='Cluster')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to better write this\n",
    "skills_clusters = tsne_projection.index.droplevel(0).to_series().groupby(cluster_labels).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, skills in skills_clusters.items():\n",
    "    print(cluster)\n",
    "    print(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = []\n",
    "\n",
    "for cluster, skills in skills_clusters.items():\n",
    "    cluster_sum = skills_ohe.droplevel(0, axis=1)[skills].sum(axis=1)\n",
    "    cluster_sum.name = cluster\n",
    "    new_features.append(cluster_sum)\n",
    "\n",
    "fe_clustered_skills = pd.concat(new_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_clustered_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train / test matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_df = pd.concat([fe_clustered_skills, \n",
    "                                  skills_ohe.droplevel(0,axis=1)], \n",
    "                                 axis=1)\n",
    "roles_df = ohe_df['DevType'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(combined_features_df, roles_df, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute samples weight to deal with classes imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign class weight as an inverse of its frequency \n",
    "class_weights = (1 / roles_df.sum(axis=0))\n",
    "\n",
    "# Multiply class weights with the 1 hot encoded values and get the mean of each sample\n",
    "sample_weight = np.multiply(class_weights.values, Y_train.values).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute samples weight to deal with classes imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_from_confusion_matrix(confusion_matrix):\n",
    "    return (confusion_matrix[1,1] / \n",
    "            (confusion_matrix[1,1] + \n",
    "             (0.5 * (confusion_matrix[0,1] + confusion_matrix[1,0]))\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {'original': skills_ohe.droplevel(0,axis=1).columns.tolist(), \n",
    "                'clusters': fe_clustered_skills.columns.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for feature_set_name, feature_set in feature_sets.items():\n",
    "    # Create sub trainings\n",
    "    sub_train = X_train[feature_set].copy()\n",
    "    sub_test  = X_test[feature_set].copy()\n",
    "    \n",
    "    # Train classifier \n",
    "    clf = MultiOutputClassifier(LogisticRegression())\n",
    "    clf.fit(sub_train, Y_train, sample_weight=sample_weight)\n",
    "\n",
    "    # Calcaulte F1 for training data\n",
    "    multilabel_confusion_matricies = multilabel_confusion_matrix(Y_train, clf.predict(sub_train))\n",
    "    f1_train_scores = [f1_from_confusion_matrix(matrix) \n",
    "                       for matrix in multilabel_confusion_matricies]\n",
    "\n",
    "    # Calcaulte F1 for testing data\n",
    "    multilabel_confusion_matricies = multilabel_confusion_matrix(Y_test, clf.predict(sub_test))\n",
    "    f1_test_scores = [f1_from_confusion_matrix(matrix) \n",
    "                       for matrix in multilabel_confusion_matricies]\n",
    "\n",
    "    # Add to results\n",
    "    set_result = pd.DataFrame({\"train\": f1_train_scores, \"test\":f1_test_scores}, \n",
    "                              index=roles_df.columns.to_list())\n",
    "    results[feature_set_name] = set_result.sort_values('test')\n",
    "    \n",
    "    \n",
    "    # Print\n",
    "    print(\"Feature set: \" + feature_set_name)\n",
    "    print(\".. Mean train F1:\", np.mean(f1_train_scores))    \n",
    "    print(\".. Mean test F1:\", np.mean(f1_test_scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = os.path.join(EXPORT_FEATURES_DIR, \"features_skills_clusters.pkl\")\n",
    "fe_clustered_skills.to_pickle(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_path = os.path.join(EXPORT_FEATURES_DIR, \"features_skills_clusters_description.yaml\")\n",
    "with open(description_path, 'w') as outfile:\n",
    "    yaml.dump(skills_clusters.to_dict(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
